# 架构篇：系统架构与技术选型

<div class="image-container">
    <img src="./docs/im/images/54.png" alt="图片10-1" title="图片10-1" >
    <span class="image-title">图 10-1 </span>
</div>

## 系统架构

首先，我们给实战项目取个霸气点的名字：King IM Cloud（简写KIM）。

在分布式的架构及演进一章中，我已经给出了通信服务的架构图。那么在本章节我们从全局的视角，看看整个系统完整的架构图：

<div class="image-container">
    <img src="./docs/im/images/55.png" alt="图片10-2" title="图片10-2" >
    <span class="image-title">图 10-2 </span>
</div>

整个系统核心由6个核心服务组成，它们分别是：ApiGateway、Router、TGateway/WGateway、LoginServer、ChatServer、IMService。

1. ApiGateway: API接口网关，对外开放部分Service提供的服务。
2. Royal: RPC服务，在后面章节Service也是指这个服务。提供了用户管理、群管理、消息管理、登录授权等服务。
3. Router：网关层智能路由，SDK通过调用Router提供的接口路由到指定的网关。
4. WGateway/TGateway：长连接网关，它们功能完全相同，WGateway提供Websocket协议的连接服务，TGateway提供TCP协议的连接服务。
5. LoginServer: 登录服务，提供登录、退出等服务，会话保存在redis中。
6. ChatServer: 聊天服务，提供单聊、群聊、离线消息同步等功能。

下面我们通过一个简化的时序图来看看服务之间的调用关系：

<div class="image-container">
    <img src="./docs/im/images/56.png" alt="图片10-3" title="图片10-3" >
    <span class="image-title">图 10-3 </span>
</div>

主要有两个逻辑：授权登录与单聊消息，整个系统都是以这两个逻辑为核心展开，实际上内部的逻辑还是比较复杂的。我们从系统分层及模块的角度来看下内部大致结构：

<div class="image-container">
    <img src="./docs/im/images/57.png" alt="图片10-4" title="图片10-4" >
    <span class="image-title">图 10-4 </span>
</div>

其中通信相关的核心模块：

1. 连接监听与管理：监控端口，并接收客户端的连接，维护在内存中。
2. 消息处理单元：解析接收的消息并处理。
3. 负载与路由：根据策略把消息发送到指定的服务中。
4. 逻辑服务管理：维护与逻辑服务的长连接，收/发消息。
5. 网关监听与管理：监控端口，并接收网关的连接，维护在内存中。
6. 指令路由器：类似于Http中的路由，通过协议头中的指令找到指令处理器。
7. 会话管理：管理系统登录的会话，会话存储在缓存Redis中。

> 具体的细节我们在之后的章节一一道来。

## 技术选型

开发一套系统，其中使用的技术与框架是非常多的，有些需要我们自己实现，而有些则可以使用开源的成熟方案，减少不必要的工作量。当然在使用的过程中，我们也搞明白它的大致原理，拿来主义虽然没错，但是如果因此导致系统出了bug，这个锅也甩不掉哈。话不多说，我们来看看在本小册IM系统中使用了那些技术。

<div class="image-container">
    <img src="./docs/im/images/58.png" alt="图片10-5" title="图片10-5" >
    <span class="image-title">图 10-5 </span>
</div>

### 分布式唯一ID

在高并发的业务场景中，系统往往会在短时间内产生大量的消息，比如10w+，为了不阻塞依赖此消息主键的下游服务，在把消息插入数据库之前，我们需要给这些消息先打上一个ID，由于服务通常是一个集群，因此需要保证生成的消息ID是全局唯一，否则后面写入数据库就会冲突。

同时，在分布式存储系统中，也需要考虑分布式唯一ID的问题，离我们最近的场景就是数据库的双向同步，比如Mysql中的双主模式，可以同时向两个数据库写数据，但前提是主键不能冲突，如下图。

<div class="image-container">
    <img src="./docs/im/images/59.png" alt="图片10-6" title="图片10-6" >
    <span class="image-title">图 10-6 </span>
</div>

实际上很多系统在早期，由于对可用性要求不是非常高，技术负责人也没有分布式系统相关经验，往往直接采用数据库的自增ID，但是当系统复杂度与用户量上升到另一个级别后，可能就需要考虑做多数据中心容灾，这时候再考虑数据主键冲突问题，改动工作量就有点大了。然而在系统设计前期就使用分布式ID作为数据的主键，成本实际上是非常低的。

在本小册的实战项目中，分布式唯一ID最核心的使用场景就是消息存储，其次就是业务表，比如用户，群之类的。

在IM系统中分布式唯一ID主要考虑有以下几点：

* 有序性：提高数据库插入性能。
* 可用性：可保证高并发下的可用性。
* 友好性：尽量简单易用，不增加系统负担。

其中有序性是从数据库的Insert性能考虑的，比如我们使用的Mysql中主键是B+树索引，在写入数据时如果主键是有序的，索引树达到平衡的代价就最小，写入性能也就最高了。另一方面索引值越小，在内存单位页中保存的索引数量就越多，查询效率就越高，因此我们只考虑使用数字作为主键，像一些字符串之类的分布式唯一ID方案就不考虑了。

最后，我们看看下面三种方案大致的对比情况：

| 数据库自增主键 | 分布式ID服务 | 雪花算法 |
| -------------- | ------------ | -------- |
| 有序性         | +++          | ++       | +++ |
| 可用性         | +            | ++       | +++ |
| 友好性         | +++          | +        | ++  |

* 数据库自增主键实际上就是依赖数据库的自增ID了，只不过在起点和步长设置上与单节点不同，比如A节点从1开始自增，步长为2；B节点从2开始自增，步长为2，多节点同理，不过这个方案后期数据要迁移变动代价也很高。
* 分布式ID服务需要维护一套ID服务，增加了系统复杂性，当然如果公司里已经有统一的ID服务当然是最理想的情况。
* 而雪花算法只要保证每个计算节点编号NodeID不重复，基本上不会产生冲突的ID，性能也非常高。

综合来说雪花算法算是各方面比较平稳的选择。

> 由于篇幅有限，三种及更多的分布式ID方案的原理就不在这里详细讲解了，感兴趣的读者可以自行查阅相关资料。

本项目使用 [github.com/bwmarrin/sn… ](https://github.com/bwmarrin/snowflake)生成分布式ID。

<div class="image-container">
    <img src="./docs/im/images/60.png" alt="图片10-7" title="图片10-7" >
    <span class="image-title">图 10-7 </span>
</div>

> 读者注意下，Timestamp是在NodeID的高位，因此它可能保证多节点下生成的ID都是随着时间在增大的。

示例如下：

```golang
// Create a new Node with a Node number of 1
node, err := snowflake.NewNode(1)
if err != nil {
        fmt.Println(err)
        return
}
// Generate a snowflake ID.
id := node.Generate()
// Print out the ID in a few different ways.
fmt.Printf("Int64  ID: %d\n", id)
```

使用snowflake对有两点要注意：

* Make sure your system is keeping accurate system time
* Make sure you never have multiple nodes running with the same node ID

第一点，这个就是运维干的事了，一般服务器都会使用NTP来同步时间。

> NTP（Network Time Protocol，网络时间协议）是由RFC 1305定义的时间同步协议，用来在分布式时间服务器和客户端之间进行时间同步。NTP基于UDP报文进行传输，使用的UDP端口号为123。

第二点，可以在启用服务手动指定，也可以由运维注入系统（容器）的环境变量中，程序直接读取出。

### RPC框架

> RPC框架 = 通信协议+序列化

我们主要从以下两种中选一种：

| REST     | GPRC     |
| -------- | -------- |
| 通信协议 | HTTP/1.1 | HTTP/2   |
| 序列化   | Json     | Protobuf |

> 严格来说REST接口也不算标准的RPC框架，不过它不是本小册的重点，因此不准备在这方面花费太多时间精力。

如果从性能的方面考虑，GPRC使用HTTP/2协议作为通信协议，而HTTP/2是长连接相比HTTP/1.1性能肯定是要好的，而且它使用protobuf使用消息的序列化框架，在基础篇：网络传输详解一章中我们也对比过，protobuf在性能与空间占用方面比json好很多。不过GRPC也有一些缺点：

* 长连接会导致SLB负载不均衡。
* GRPC服务注册与发现相对复杂些。
* 测试不友好。

综合考虑，在小册的实战项目中直接使用rest接口。在golang中http框架有很多，比如:

* [github.com/gin-gonic/g…](https://github.com/gin-gonic/gin)
* [github.com/labstack/ec…](https://github.com/labstack/echo)
* [github.com/kataras/iri…](https://github.com/kataras/iris)

它们性能相差不大，本小册就直接使用iris开发rest服务了，至于为什么选它，先来看下这张摘自iris文档中的图片：

<div class="image-container">
    <img src="./docs/im/images/61.png" alt="图片10-8" title="图片10-8" >
    <span class="image-title">图 10-8 </span>
</div>

它的调用方式与java中Springboot MVC框架有点类似，搞java的读者会有亲切感，感兴趣的读者可以看看它的使用教程。不过选择iris开发rest接口主要有如下原因：

* 性能高
* 支持Protobuf

文档： [www.iris-go.com/docs/](https://www.iris-go.com/docs/)。

### 序列化框架

序列化框架可选项有很多，在这里我列举了三种序列化实现方式：

* protobuf
* json
* 自定义

这三种框架已经在基础篇：网络传输详解介绍过了，这里就不详解了。在本项目中，会同时使用到protobuf和自定义序列化，我们在后面具体的协议章节再介绍细节。

官方文档：[developers.google.com/protocol-bu…](https://developers.google.com/protocol-buffers/docs/proto3)。

总结下它的优点：

* 性能好
* 序列化之后的空间小
* 支持向后兼容和向前兼容
* 支持多种编程语言

缺点就是要安装环境，要提前编译.proto文件，而且版本升级可能导致以前的逻辑错误。

### websocket框架

在我们开发的网关中使用到了websocket协议，因此我们需要选择一个websocket库来帮我们减少工作量，在golang中也有一些选择，比如：

* [github.com/gorilla/web… ](https://github.com/gorilla/websocket)15k Star
* [github.com/gobwas/ws](https://github.com/gobwas/ws) 3.9k Star

gorilla的版本使用上要比gobwas更简单，也就是傻瓜式调用。而gobwas对底层的逻辑开放的更多，使用时需要有一点websocket协议基础知识，如果把gorilla比作ios系统，gobwas就是开源的android系统。在本小册中我们使用gobwas开发通信层逻辑，选择它也是因为gobwas可控性更高，我们在后期会针对websocket接入逻辑做性能优化，这里就先卖个关子。

### orm框架

在golang中orm框架也是一堆，我选择两个比较熟悉也是使用比较多的ORM框架，如下：

* gorm

<div class="image-container">
    <img src="./docs/im/images/62.png" alt="图片10-9" title="图片10-9" >
    <span class="image-title">图 10-9 </span>
</div>

* xorm

<div class="image-container">
    <img src="./docs/im/images/63.png" alt="图片10-10" title="图片10-10" >
    <span class="image-title">图 10-10 </span>
</div>

它们功能都相差不大，图中红色标记是一些重点使用的功能。从图中也可以看出一点区别，我挑几个重点的说明一下：

gorm优点

* 事务使用方便。
* 支持多数据源。
* Prometheus支持。
* 驱动支持Clickhouse。

xorm优点

* 支持缓存。
* 支持乐观锁。
* 驱动支持TiDB。

比较下来，还是gorm优点对本项目的更有利。比如它的事务调用就比xorm方便很多：

```golang
db.Transaction(func(tx *gorm.DB) error {
  // 在事务中执行一些 db 操作（从这里开始，您应该使用 'tx' 而不是 'db'）
  if err := tx.Create(&Animal{Name: "Giraffe"}).Error; err != nil {
    // 返回任何错误都会回滚事务
    return err
  }
  if err := tx.Create(&Animal{Name: "Lion"}).Error; err != nil {
    return err
  }
  // 返回 nil 提交事务
  return nil
})
```

### 中间件选型

在如今这个大流量时代，中间件已经是不可或缺的部分。常有如下几类：数据库、缓存、MQ、注册中心、配置中心、文件存储等，而都有很多开源产品。不过，本小册中对中间件选择没有强制要求。在编码实战部分，这些外部依赖都会通过接口抽象出来，核心系统不会直接依赖具体的实现。因此这里只是简单介绍下系统使用到的中间件。

数据库：主要作用是存储用户、群等基本信息的库。还有一个存储离线消息的库。如果对业务上估计下来每天的消息量在百万左右，完全是可能使用mysql来支撑的。如果有更大量的需求，可以切换到TiDB或者Clickhouse，这非常灵活，完全取决于你对成本的考虑。

缓存：本项目使用会Redis为会缓存，主要考虑它性能高，也有高可用方案，如最常用的哨兵模式和集群模式，而且还有相应的运维系统，如cachecloud。

注册中心：它是微服务体系的一个核心中间件，实现了服务的注册与发现。开源产品很多，通常分为CP(保证数据一致性)和AP（保证服务可用性）两个大类，比如ETCD、Consul，Nacos等就是CP类的注册中心，Eureka就是AP类的注册中心。在本实战项目中，由于涉及到多个服务之间的通信，因此也会使用到注册中心。在实战项目中我们选择使用golang开发的Consul，详细内容会在服务注册与发现一章中介绍。

配置中心：配置中心可以统一管理配置并且热修改，不过它不是一个必须的组件，因此在本项目中暂不集成配置中心。

文件存储：通常使用OSS（比如阿里OSS）作为图片的存储方案，在IM系统中发送的图片与视频通常是先上传到OSS，再把url通过消息发送出去，不过在本项目不准备实现图片语音消息的逻辑，因此也不会涉及文件存储。

## 最后总结

相信看完本章，读者对整个系统有了一个大致的了解。同时本章也介绍了很多技术与中间件，可能一些新手读者有点慌，这是正常情况，不过只要跟着小册学习，相信读者会有很大的收获。从下一章节开始，我们将从通信服务的底层开始，完成第一个里程碑。请读者系好安全带，准备起飞~

本章完！