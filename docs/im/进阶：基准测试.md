# 进阶：基准测试

<div class="image-container">
    <img src="./docs/im/images/172.png" alt="图片24-1" title="图片24-1" >
    <span class="image-title">图 24-1 </span>
</div>

> 如果只想看结果，请看本章最后总结部分。

## 简介

### 什么是基准测试

基准测试是指通过设计科学的测试方法、测试工具和测试系统，实现对一类测试对象的某项性能指标进行定量的和可对比的测试。例如，对计算机CPU进行浮点运算、数据访问的带宽和延迟等指标的基准测试，可以使用户清楚地了解每一款CPU的运算性能及作业吞吐能力是否满足应用程序的要求。

基准测试有七个重要特征。这些关键属性是：

1. 相关性：基准应该衡量相对重要的特征。
2. 代表性：基准性能指标应被业界和学术界广泛接受。
3. 公平：所有系统都应该被公平地比较。
4. 重复性：可以验证基准测试结果。
5. 成本效益：基准测试是经济的。
6. 可扩展性：基准测试应该适用于拥有从低到高的一系列资源的系统。
7. 透明度：基准指标应该易于理解。

简单来说，基准测试是针对系统设计的一种压力测试，目的是为了掌握系统的行为或可靠性。它是一种成本较低的可以学习系统在给定的工作负载下性能表现情况的一种非常有效的方法。

基准测试无法模拟真实环境下系统的压力表现，这很好理解，因为真实现环境下的影响因素太多并且多变。比如一个数据库实例被多个服务调用，但是它的IO吞吐量是有限的，在真实环境下就会互相影响。而基准测试则是在单一的条件下，在尽量短的时间内完成测试，通常对系统某方面造成较大的压力。

### 基准测试的策略

基准测试有两种主要策略：一是针对整个系统的整体测试，另外是单独对系统中分层做测试。这两种策略也被称为集成式（full-stack）以及分层（single-layer）基准测试。我们分别来了解下它们的区别：

* 分层测试指对系统中核心层级单独做测试，当然不同的系统的它们的层级划分不同，考量的指标也不相同。比如对一个传统的HTTP服务做分层测试，可能就需要引入mock技术，去掉外部依赖的影响，单独测试服务的性能。它的优点主要有以下几点：
    * 减少了非相关因素对测试结果的影响，具有更高的针对性，可以帮忙我们建立更准确的优化指标。
    * 测试成本更低，无须部署一整套完整的系统就可以进行。
    * 指标更透明，易于理解。
* 集成式测试指对整个系统做链路测试，这是相对困难的，首先你至少要部署一整套系统。特别是在生产环境中，还需要考虑到测试过程中生产的脏数据对系统的影响。同时测试工具自身的的局限也会影响结果的有效性。

> 在本章节，我们主要从整体角度来测试系统的性能。

### 度量指标

在开始执行基准测试之前，需要先明确测试的目标。测试目标决定了选择什么样的测试工具和技术，以获得精确而有意义的测试结果。通常考虑如下几个指标：

* 响应时间(RT)：

这个指标用于测试任务所需的时间，单位通常是微秒、毫秒或秒。比如一次redis的Get请求的响应时间以微秒算计，一次HTTP服务的Get请求的响应时间通常在5到100毫秒之间，而一次页面的加载完成通常会在1秒以上。在实际情况下，响应时间又可以分为最小响应时间、平均响应时间、最大响应时间。最大响应时间意义不大，通常是系统在高负载或者被阻塞之后导致，而且这个值不可复现。通常情况下我们使用百分比响应时间来评估一次请求或者任务的响应时间，例如，一个请求90% 情况下的响应时间为15毫秒以内，那么就可以说这个任务在正常情况下的响应时间RT为15毫秒，也就是0.015秒。

* 吞吐量（QPS、TPS）：

吞吐量是指系统在单位时间内处理请求的数量，TPS、QPS都是吞吐量的常用量化指标。

> QPS：Queries Per Second 查询次数/秒。
> TPS：Transactions Per Second 事务数/秒。

这两个概念在不同的系统中意义不同，比如在数据库中，通常用TPS表示数据库的读写性能。在web系统中，TPS中一次事务表示访问一个站点从开始到加载完全的过程，这其中会有多次请求发生，比如获取用户信息、加载资源等，因此一次事务（Transaction）等于至少一次的查询（Query）。

在本小册章节中，我们使用RPS来表示吞吐量，减少不必要的概念冲突。

> RPS：Requests Per Second 请求次数/秒。

* 并发数Co：

并发数(Concurrency)是指系统同时能处理的请求数量，这是一个经常被误解的指标，大多数人把它与吞吐量搞混，比如经常被谈起的高并发，而实际上在HTTP这类短连接的服务中，一台服务节点的并发性在于它能同时处理的连接数，也就是说它是没有时间维度的。因此我们可以得出一个大致的结论：

`RPS(吞吐量)=Co（并发数）/RT（响应时间）`

比如：并发数为10，响应时间为0.5秒，那么吞吐量就是 10/0.5 = 20 RPS。当然，在真实环境下，并发数的增加并不一定能提高吞吐量，比如大量线程的上下文切换导致系统性能下降，或者性能瓶颈在数据库读写IO上。

> 最终我们可以得到一个简单的结论：并发性与吞吐量和响应时间不同，它更像是测试过程中的一个变量，而不是一个结果，这一点也会在下面的测试工具中体现出来。

* 可扩展性：

简单来说，可扩展指通过增加一倍的资源（比如增加一个计算节点），就可以获得两倍的吞吐量。当然，绝大多数系统是不可能线性增长的，随着压力的增加，通常吞吐量会越来越差。

通常分布式系统的特点是可以水平扩展，通过增加节点达到提高吞吐量的目的，但是它受限于木桶理论，即一只木桶盛水的多少，并不取决于桶壁上最高的那块木块，而恰恰取决于桶壁上最短的那块。比如在Web服务中，大多数情况下系统的性能都会受到关系型数据库的影响，因此这也是缓存大行其道的根本原因。

同样的道理，在KIM中，我们可以通过扩展网关或者逻辑服务器来提高系统的的并发性，但是如果消息的写性能无法扩展，那么它就会成为消息转发吞吐量的天花板。而另一个性能瓶颈就是Redis会话读取了，在群的消息扩散转发中，高频的消息转发情况下，群成员的寻址过程可以很轻松达到单节点的Redis读性能上限。

## 测试工具

### kimbench介绍

由于IM的特殊性，很难有通用的基准测试工具拿到直接使用。因此，我们开发了一个基准测试工具kimbench。读者可以自己编译，或者从github中下载编译好的执行文件。地址如下：

* [kim/examples/kimbench](https://github.com/klintcheng/kim/tree/master/examples/kimbench)

<div class="image-container">
    <img src="./docs/im/images/173.png" alt="图片24-2" title="图片24-2" >
    <span class="image-title">图 24-2 </span>
</div>

首先，进入kim/examples/目录，然后：

1. 如果未编译，可以直接执行命令：`go run main.go benchmark`
2. 编译之后再执行，执行命令：`go build -o ./bin/kimbench` -> `./bin/kimbench benchmark`

如下是在控制台输出的命令提示：

```csharp
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark
kim benchmark tools

Usage:
  kim benchmark [command]

Available Commands:
  group
  login
  user

Flags:
  -a, --address string     server address (default "ws://124.71.204.19:8000")
  -s, --appSecret string   app secret (default "jwt-1sNzdiSgnNuxyq2g7xml2JvLArU")
  -c, --count int          request count (default 100)
  -h, --help               help for benchmark
  -t, --thread int         thread count (default 10)
```

它有三个子命令：

* login: 登录基准测试工具。
* user: 单聊基准测试工具。
* group：群消息基准测试工具。

四个全局变量：

* address：网关地址，默认地址为临时测试服务，读者可以通过docker-compose运行kim系统测试。
* appSecret：登录授权的密钥，必须与网关中的相同。
* count : 请求次数，不同任务中意义不同，默认为100.
* thread: 并发数，通常为线程池的大小，默认为10。

### 测试结果说明

如下是执行一次测试之后在控制台的输出内容：

```less
[~]# ./kimbench benchmark login -c 100

Summary:
  Total:	0.1036 secs
  Slowest:	0.0126 secs
  Fastest:	0.0080 secs
  Average:	0.0100 secs
  Requests/sec:	955.2099

Response time histogram:
  0.008 [1]	|■
  0.009 [21]	|■■■■■■■■■■■■■■■■■■■■■■
  0.010 [38]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.011 [35]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.013 [5]	|■■■■■

Latency distribution:
  10% in 0.0088 secs
  50% in 0.0101 secs
  75% in 0.0106 secs
  90% in 0.0111 secs
  99% in 0.0126 secs

Status code distribution:
  [0]	100 responses
```

它主要分为四部分：

1. Summary: 结果摘要。
2. Response time histogram：响应时间RT直方图。
3. Latency distribution：响应时间RT分布图。
4. Status code distribution: 响应状态码分布图。

其中，摘要就包括执行总时间、最慢RT、最快RT、平均RT、RPS等重要信息。

重要指标结果解读：

1. RPS为 955.2099。
2. 在RT直方图中，有38个登录RT为0.010秒。
3. 75%的登录RT在0.0106内，90%的登录RT在0.0111内。
4. 一共有100个请求，返回状态码都为0（成功）。

> 如果有error返回，也会显示出来。

## 测试实战

### 环境准备

测试环境：

* 华为云耀云服务器（临时）。部署了consul、redis、gateway、server、royal五个服务。

<div class="image-container">
    <img src="./docs/im/images/174.png" alt="图片24-3" title="图片24-3" >
    <span class="image-title">图 24-3 </span>
</div>

* 华为云数据库Mysql（临时）

<div class="image-container">
    <img src="./docs/im/images/175.png" alt="图片24-4" title="图片24-4" >
    <span class="image-title">图 24-4 </span>
</div>

客户端配置：

在操作系统中，会有默认的端口范围、最大连接数等限制。在测试并发连接时可能会因此导致连接被关闭测试失败，因此，如果在本机运行kimbench工具，需要修改相关配置，以Mac为例：

```shell
### 设置系统最大连接数 1048600
$ sudo sysctl -w kern.maxfiles=1048600 

### 设置进程连接数限制 1048576，进程的最大连接数要小于等于全局连接数
$ sudo sysctl -w kern.maxfilesperproc=1048576 

### 设置当前shell能打开的最大文件数为 1048576，该值不能大于 kern.maxfilesperproc ，否则会提示设置失败。
$ ulimit -n 1048576

## 表示修改动态端口的起始地址为 32768。
$ sysctl -w net.inet.ip.portrange.first=32768
```

> 为了减少网络延迟影响，以下测试都是直接在服务器上执行。

### 登录测试

在登录的基准测试中，一次请求指使用一个账号，从发起建立连接及握手认证开始，到服务端返回登录成功或者失败结束。如下图：

<div class="image-container">
    <img src="./docs/im/images/176.png" alt="图片24-5" title="图片24-5" >
    <span class="image-title">图 24-5 </span>
</div>

* 参数：200次请求、并发10

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark login -c 200 -t 10

Summary:
  Total:	0.2011 secs
  Slowest:	0.0127 secs
  Fastest:	0.0078 secs
  Average:	0.0098 secs
  Requests/sec:	989.5365

Response time histogram:
  0.008 [1]	|
  0.009 [37]	|■■■■■■■■■■■■■■
  0.010 [107]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.011 [48]	|■■■■■■■■■■■■■■■■■■
  0.013 [7]	|■■■

Latency distribution:
  10% in 0.0088 secs
  50% in 0.0098 secs
  75% in 0.0104 secs
  90% in 0.0108 secs
  99% in 0.0121 secs

Status code distribution:
  [0]	200 responses
```

* 参数：200次请求、并发20

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark login -c 200 -t 20

Summary:
  Total:	0.1205 secs
  Slowest:	0.0169 secs
  Fastest:	0.0081 secs
  Average:	0.0116 secs
  Requests/sec:	1651.5450

Response time histogram:
  0.008 [1]	|
  0.010 [37]	|■■■■■■■■■■■■
  0.013 [122]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.015 [31]	|■■■■■■■■■■
  0.017 [9]	|■■■

Latency distribution:
  10% in 0.0097 secs
  50% in 0.0114 secs
  75% in 0.0123 secs
  90% in 0.0140 secs
  99% in 0.0166 secs

Status code distribution:
  [0]	200 responses
```

* 参数：200次请求、并发100

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark login -c 200 -t 100

Summary:
  Total:	0.0684 secs
  Slowest:	0.0494 secs
  Fastest:	0.0181 secs
  Average:	0.0303 secs
  Requests/sec:	2910.3919

Response time histogram:
  0.018 [1]	|
  0.026 [105]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.034 [19]	|■■■■■■■
  0.042 [32]	|■■■■■■■■■■■■
  0.049 [43]	|■■■■■■■■■■■■■■■■

Latency distribution:
  10% in 0.0187 secs
  50% in 0.0254 secs
  75% in 0.0396 secs
  90% in 0.0479 secs
  99% in 0.0490 secs

Status code distribution:
  [0]	200 responses
```

* 参数：300次请求、并发100

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark login -c 300 -t 100

Summary:
  Total:	0.1034 secs
  Slowest:	0.0543 secs
  Fastest:	0.0154 secs
  Average:	0.0313 secs
  Requests/sec:	2890.9724

Response time histogram:
  0.015 [1]	|
  0.025 [75]	|■■■■■■■■■■■■■■■■■■■
  0.035 [161]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.045 [34]	|■■■■■■■■
  0.054 [29]	|■■■■■■■

Latency distribution:
  10% in 0.0211 secs
  50% in 0.0290 secs
  75% in 0.0346 secs
  90% in 0.0438 secs
  99% in 0.0534 secs

Status code distribution:
  [0]	300 responses
```

总结：登录由于只涉及到Redis缓存的性能与系统自身的性能影响，因此吞吐量可以轻松达到3000Rps左右。而且整个系统还是部署在一台很差的单节点之上。

### 单聊测试

在单聊的基准测试中，一次请求指使用一个账号，发送一条消息给另一个用户，并等待响应结果，在消息的测试中，是不包括登录这个时间段的。如下图：

<div class="image-container">
    <img src="./docs/im/images/177.png" alt="图片24-6" title="图片24-6" >
    <span class="image-title">图 24-6 </span>
</div>

* 参数：200次请求、并发10

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark user -c 200 -t 10

Summary:
  Total:	0.3677 secs
  Slowest:	0.0269 secs
  Fastest:	0.0133 secs
  Average:	0.0181 secs
  Requests/sec:	541.2120

Response time histogram:
  0.013 [1]	|
  0.017 [82]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.020 [56]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.023 [52]	|■■■■■■■■■■■■■■■■■■■■■■■■■
  0.027 [9]	|■■■■

Latency distribution:
  10% in 0.0143 secs
  50% in 0.0176 secs
  75% in 0.0207 secs
  90% in 0.0227 secs
  99% in 0.0268 secs

Status code distribution:
  [0]	200 responses
```

* 参数：200次请求、并发20

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark user -c 200 -t 20

Summary:
  Total:	0.2415 secs
  Slowest:	0.0382 secs
  Fastest:	0.0143 secs
  Average:	0.0231 secs
  Requests/sec:	824.1310

Response time histogram:
  0.014 [1]	|■
  0.020 [67]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.026 [76]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.032 [47]	|■■■■■■■■■■■■■■■■■■■■■■■■■
  0.038 [9]	|■■■■■

Latency distribution:
  10% in 0.0172 secs
  50% in 0.0227 secs
  75% in 0.0270 secs
  90% in 0.0286 secs
  99% in 0.0352 secs

Status code distribution:
  [0]	200 responses
```

* 参数：200次请求、并发100

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark user -c 200 -t 100

Summary:
  Total:	0.1751 secs
  Slowest:	0.1155 secs
  Fastest:	0.0303 secs
  Average:	0.0662 secs
  Requests/sec:	1136.6193

Response time histogram:
  0.030 [1]	|■
  0.052 [56]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.073 [74]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.094 [44]	|■■■■■■■■■■■■■■■■■■■■■■■■
  0.116 [25]	|■■■■■■■■■■■■■■

Latency distribution:
  10% in 0.0406 secs
  50% in 0.0635 secs
  75% in 0.0803 secs
  90% in 0.0963 secs
  99% in 0.1154 secs

Status code distribution:
  [0]	200 responses
```

* 参数：300次请求、并发100

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark user -c 300 -t 100

Summary:
  Total:	0.2274 secs
  Slowest:	0.1265 secs
  Fastest:	0.0294 secs
  Average:	0.0659 secs
  Requests/sec:	1314.9719

Response time histogram:
  0.029 [1]	|
  0.054 [97]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.078 [129]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.102 [42]	|■■■■■■■■■■■■■
  0.127 [31]	|■■■■■■■■■■

Latency distribution:
  10% in 0.0427 secs
  50% in 0.0614 secs
  75% in 0.0766 secs
  90% in 0.1023 secs
  99% in 0.1238 secs

Status code distribution:
  [0]	300 responses
```

* 参数：500次请求、并发100

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark user -c 500 -t 100

Summary:
  Total:	0.3306 secs
  Slowest:	0.1131 secs
  Fastest:	0.0220 secs
  Average:	0.0600 secs
  Requests/sec:	1509.1981

Response time histogram:
  0.022 [1]	|
  0.045 [90]	|■■■■■■■■■■■■■■
  0.068 [259]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.090 [121]	|■■■■■■■■■■■■■■■■■■■
  0.113 [29]	|■■■■

Latency distribution:
  10% in 0.0380 secs
  50% in 0.0592 secs
  75% in 0.0698 secs
  90% in 0.0819 secs
  99% in 0.1025 secs

Status code distribution:
  [0]	500 responses
```

总结：单聊消息的吞吐量随着并发数和请求数的增加，吞吐量也是比较线性的在增加，甚本上在1500Rps以上。

### 群聊测试

在群聊的基准测试中，一次请求指使用一个账号，发送一条消息到一个群，并等待响应结果，在消息的测试中，不包括登录这个时间段的。如下图：

<div class="image-container">
    <img src="./docs/im/images/178.png" alt="图片24-7" title="图片24-7" >
    <span class="image-title">图 24-7 </span>
</div>

在群的测试中，还有两个参数：

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark group --help
Usage:
  kim benchmark group [flags]

Flags:
  -h, --help             help for group
  -m, --memcount int     member count (default 20)
  -p, --percet float32   online percet (default 0.5)
```

> 默认为20人群，50%成员在线就是10人。

* 参数：200次请求、并发10、群成员20人、50%成员在线。

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark group -c 200 -t 10

Summary:
  Total:	1.2498 secs
  Slowest:	0.6469 secs
  Fastest:	0.0193 secs
  Average:	0.0336 secs
  Requests/sec:	159.2298

Response time histogram:
  0.019 [1]	|
  0.176 [197]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.333 [1]	|
  0.490 [0]	|
  0.647 [1]	|

Latency distribution:
  10% in 0.0236 secs
  50% in 0.0298 secs
  75% in 0.0361 secs
  90% in 0.0426 secs
  99% in 0.3021 secs

Status code distribution:
  [0]	200 responses
```

* 参数：200次请求、并发20、群成员20人、50%成员在线。

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark group -c 200 -t 20

Summary:
  Total:	1.0678 secs
  Slowest:	0.7004 secs
  Fastest:	0.0225 secs
  Average:	0.0542 secs
  Requests/sec:	186.3638

Response time histogram:
  0.022 [1]	|
  0.192 [192]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.361 [3]	|■
  0.531 [2]	|
  0.700 [2]	|

Latency distribution:
  10% in 0.0310 secs
  50% in 0.0432 secs
  75% in 0.0506 secs
  90% in 0.0578 secs
  99% in 0.6586 secs

Status code distribution:
  [0]	200 responses
```

* 参数：200次请求、并发100、群成员20人、50%成员在线。

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark group -c 200 -t 100

Summary:
  Total:	0.3201 secs
  Slowest:	0.2114 secs
  Fastest:	0.0476 secs
  Average:	0.1337 secs
  Requests/sec:	621.6110

Response time histogram:
  0.048 [1]	|
  0.089 [10]	|■■■■■
  0.129 [88]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.170 [69]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.211 [32]	|■■■■■■■■■■■■■■■

Latency distribution:
  10% in 0.0965 secs
  50% in 0.1308 secs
  75% in 0.1581 secs
  90% in 0.1837 secs
  99% in 0.2098 secs

Status code distribution:
  [0]	200 responses
```

* 参数：300次请求、并发100、群成员20人、50%成员在线。

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark group -c 300 -t 100

Summary:
  Total:	1.1432 secs
  Slowest:	0.8135 secs
  Fastest:	0.0583 secs
  Average:	0.1404 secs
  Requests/sec:	261.5414

Response time histogram:
  0.058 [1]	|
  0.247 [297]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.436 [0]	|
  0.625 [0]	|
  0.813 [2]	|

Latency distribution:
  10% in 0.1005 secs
  50% in 0.1357 secs
  75% in 0.1623 secs
  90% in 0.1826 secs
  99% in 0.2391 secs

Status code distribution:
  [0]	300 responses
```

* 参数：200次请求、并发100、群成员50人、50%成员在线。

```cmd
[root@hecs-x-large-2-linux-20210831100334 ~]# ./kimbench benchmark group -c 200 -t 100 -m 50

Summary:
  Total:	1.8774 secs
  Slowest:	1.6684 secs
  Fastest:	0.0576 secs
  Average:	0.2775 secs
  Requests/sec:	105.9979

Response time histogram:
  0.058 [1]	|
  0.460 [183]	|■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■
  0.863 [8]	|■■
  1.266 [2]	|
  1.668 [6]	|■

Latency distribution:
  10% in 0.1399 secs
  50% in 0.2081 secs
  75% in 0.2612 secs
  90% in 0.4099 secs
  99% in 1.6192 secs

Status code distribution:
  [0]	200 responses
```

总结：在群的测试中，可以显示看到成员数据的增加对吞吐量的影响非常大，这也与我们的后端逻辑有直接的关系。

## 最后总结

可以看到，在未有任何优化的前提下，一个单机环境的Kim服务的性能测试结果如下：

| 任务         | RPS       | Fastest     | Average     | 90% distribution |
| ------------ | --------- | ----------- | ----------- | ---------------- |
| 登录         | 2890.9724 | 0.0154 secs | 0.0313 secs | 0.0438 secs      |
| 单聊         | 1509.1981 | 0.0220 secs | 0.0600 secs | 0.0819 secs      |
| 群聊（20人） | 621.6110  | 0.0476 secs | 0.1337 secs | 0.1837 secs      |

本章完！