# 基础篇：网络传输详解

经过前面几个章节的学习，相信读者对长连系统多少有了一定的理解。部分读者应该都听说过粘包与解包、网络字节序、缓冲等网络通信方向的知识，有些读者可能也有些疑问，比如：

1. 不是说tcp传输数据时会粘包吗，怎么在前面demo章节中没有发生这个现象？
2. 网络字节序是什么？
3. 缓冲在什么情况下使用？

因此，本章我们来聊聊这方面的知识点！

<div class="image-container">
    <img src="./docs/im/images/37.png" alt="图片8-1" title="图片8-1" >
    <span class="image-title">图 8-1 </span>
</div>

## 网络字节序

在计算机运算的过程中，cpu从内存读取数据都是从低位开始的，同样在网络传输中比如读取tcp缓冲区数据也是从前往后顺序读取。比如下面存放一个字节的char和4个字节的int类型，它的内存结构图如下：

<div class="image-container">
    <img src="./docs/im/images/38.png" alt="图片8-2" title="图片8-2" >
    <span class="image-title">图 8-2 </span>
</div>

像char(rune)这类只有一个字节的类型也就没有顺序一说了，但是超过1个字节的类型如果要写到其它地方比如硬盘或网络，就需要使用统一读写顺序，比如我们把0x0201这个值按计算机理解的方式写到缓冲中，就是如下样子：

<div class="image-container">
    <img src="./docs/im/images/39.png" alt="图片8-3" title="图片8-3" >
    <span class="image-title">图 8-3 </span>
</div>

实际上这就是小端序，cpu处理时非常方便，但是这个排列顺序对人的习惯来说很不友好。如果我们按照人类习惯的顺序写入缓冲中，就是如下样子：

<div class="image-container">
    <img src="./docs/im/images/40.png" alt="图片8-4" title="图片8-4" >
    <span class="image-title">图 8-4 </span>
</div>

这个顺序看着就好多了，与我们书写的0x0201顺序相同，这就是大端序。因此，总结下来网络字节序有两种形式表示：

* 小端序：低位字节在前，高位字节在后，计算机方便处理。
* 大端序：高位字节在前，低位字节在后，与人的使用习惯相同。

示例：

```go
// golang
a := uint32(0x01020304)
arr := make([]byte, 4)
binary.BigEndian.PutUint32(arr, a)
t.Log(arr) //[1 2 3 4]

binary.LittleEndian.PutUint32(arr, a)
t.Log(arr) //[4 3 2 1]
```

在网络应用中，字节序是一个必须被考虑的因素，因为不同机器类型可能采用不同标准的字节序，所以在设计通信层协议时必须要考虑大小端问题。

> 那么字符串与字节序有关吗？读者可以理解了序列化的底层原理之后再来思考这个问题！

## 序列化

序列化(Serialization)是将对象的状态信息转换成可取用格式（例如存成文件，存于缓冲，或经由网络中发送），以留待后续在相同或另一台计算机环境中，能读取出来反序列化对象的状态，重新创建该对象。比如我们常用的序列化框架：

* Fastjson/Jackson
* Thrift
* Protobuf
* Hessian
* ...

相信读者对它们或多或少有一定了解，在本章节我不准备介绍每种序列化框架的原理与细节，而是通过下面的示例来演示序列化的核心原理，搞明白了底层原理，如果要再深入了解它们的实现差异与优缺点就不难了。

我们先来看下示例：

```golang
var pkt = struct {
        Source   uint32
        Sequence uint64
        Data     []byte
}{
        Source:   257,
        Sequence: 5,
        Data:     []byte("hello world"),
}

// 为了方便观看，使用大端序
endian := binary.BigEndian

buf := make([]byte, 1024) // buffer
i := 0
endian.PutUint32(buf[i:i+4], pkt.Source)
i += 4
endian.PutUint64(buf[i:i+8], pkt.Sequence)
i += 8
// 由于data长度不确定，必须先把长度写入buf, 这样在反序列化时就可以正确的解析出data
dataLen := len(pkt.Data)
endian.PutUint32(buf[i:i+4], uint32(dataLen))
i += 4
// 写入数据data
copy(buf[i:i+dataLen], pkt.Data)
i += dataLen
t.Log(buf[0:i])
t.Log("length", i)
```

在上面的例子中，我们模拟了一个对象序列化的过程，得出的结果，用图表示如下：

<div class="image-container">
    <img src="./docs/im/images/41.png" alt="图片8-5" title="图片8-5" >
    <span class="image-title">图 8-5 </span>
</div>

其中第一行是Pkt中第一行表示每个属性所占长度，第二行就是排列顺序，第三行是具体的值。

它有几个特点：

1. 顺序写，效率高。
2. 不会把属性key序列化进去。
3. 对[0 0 0 0 0 0 0 5]这样占用字节数多，但是值（5）很小的情况下有点浪费。
4. 实现复杂。

通过把这个pkt序列化，我们就可以把它通过网络传输到另一台主机，在接收方收到这条消息之后就可以反序列化出对象。

```golang
var pkt struct {
	Source   uint32
	Sequence uint64
	Data     []byte
}
recv := []byte{0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 11, 104, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100}
endian := binary.BigEndian
i := 0
pkt.Source = endian.Uint32(recv[i : i+4])
i += 4
pkt.Sequence = endian.Uint64(recv[i : i+8])
i += 8
dataLen := endian.Uint32(recv[i : i+4])
i += 4
pkt.Data = make([]byte, dataLen)
copy(pkt.Data, recv[i:i+int(dataLen)])
t.Logf("Src:%d Seq:%dData:%s", pkt.Source, pkt.Sequence, pkt.Data)
```

输出：

```less
Src:257 Seq:5 Data:hello world
```

### protobuf序列化

接下来我们使用protobuf序列化框架测试。首先，定义相同结构的message:

```protobuf
syntax = "proto3";
package pkt;
option go_package = "./pkt";

message Pkt {
    uint32 Source  = 1;
    uint64 Sequence = 3;
    bytes  Data = 5;
}
```

> `protoc -I proto/ --go_out=. proto/*.proto` 编译成go文件

```golang
type Pkt struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Source   uint32 `protobuf:"varint,1,opt,name=Source,proto3" json:"Source,omitempty"`
	Sequence uint64 `protobuf:"varint,3,opt,name=Sequence,proto3" json:"Sequence,omitempty"`
	Data     []byte `protobuf:"bytes,5,opt,name=Data,proto3" json:"Data,omitempty"`
}
```

我们使用与上面同样的值写个测试代码：

```golang
p := Pkt{
        Source:   257,
        Sequence: 5,
        Data:     []byte("hello world"),
}
bts, err := proto.Marshal(&p)
assert.Nil(t, err)
t.Log(bts)
t.Log("length ", len(bts))
```

得到如下的结果：

<div class="image-container">
    <img src="./docs/im/images/42.png" alt="图片8-6" title="图片8-6" >
    <span class="image-title">图 8-6 </span>
</div>

对比之前我们自己实现的序列化占用了27字节，它居然只占用18字节。读者应该也发现了，它是把uint32/257和uint64/5这样的值优化了，成了可变长度的值。我们来验证下它的逻辑：

把值改大：

```golang
p := Pkt{
    Source:   10000000,
    Sequence: 2 << 60+3, // 使最低位有值
    Data:     []byte("hello world"),
}
```

得到的结果就是：

<div class="image-container">
    <img src="./docs/im/images/43.png" alt="图片8-7" title="图片8-7" >
    <span class="image-title">图 8-7 </span>
</div>

它的长度就变成了28bytes，比我们的实现增长了1个字节。如果data的长度也是10000000，第三个值11的长度也会变成5bytes，但是前面我们自己实现的序列化长度是固定的，对比下来使用protobuf序列化时长度反而增长1+2+1=4个字节。

### json序列化

同样的对象，如果使用json序列化：

```golang
p := Pkt{
        Source:   10000000,
        Sequence: 2<<60 + 3,
        Data:     []byte("hello world"),
}

bts, err = json.Marshal(&p)
assert.Nil(t, err)
t.Log(bts)
t.Log("length ", len(bts))
```

得到如下的结果：

```ruby
$ [123 34 83 111 117 114 99 101 34 58 49 48 48 48 48 48 48 48 44 34 83 101 113 117 101 110 99 101 34 58 50 51 48 53 56 52 51 48 48 57 50 49 51 54 57 51 57 53 53 44 34 68 97 116 97 34 58 34 97 71 86 115 98 71 56 103 100 50 57 121 98 71 81 61 34 125]
$ {"Source":10000000,"Sequence":2305843009213693955,"Data":"aGVsbG8gd29ybGQ="}
$ length  76
```

序列化之后的长度是76bytes，这个空间占用就与前面两种实现完全没有可比性了，但是它的优点就是使用简单。

> 提示：`[]byte("hello world")` 字符串转byte数组的过程就是一次编码过程，在golang中默认使用utf-8编码，utf-8是Unicode编码的一种实现方式，如果把自定义的序列化比作Unicode编码，utf-8与protobuf类似，是可变长度的编码方式。

### 性能大PK

我们对上面三种序列化方式做一个基准测试，从性能的角度看看它们的标准。

示例代码就只贴上Protobuf的：

```golang
func Benchmark_Protobuf(t *testing.B) {
	p := Pkt{
		Source:   10000000,
		Sequence: 2<<60 + 3,
		Data:     []byte("hello world"),
	}
	for i := 0; i < t.N; i++ { <-- t.N 次
		bts, err := proto.Marshal(&p)
		assert.Nil(t, err)
		assert.NotEmpty(t, bts)
	}
}
```

> 环境 cpu: Intel(R) Core(TM) i5-8257U CPU @ 1.40GHz

结果：

| name     | t.N         | ns/op | B/op | allocs/op |
| -------- | ----------- | ----- | ---- | --------- |
| 自定义   | 290,041,615 | 4.299 | 0    | 0         |
| Protobuf | 5,633,020   | 205.6 | 56   | 2         |
| Json     | 2,686,958   | 432.8 | 104  | 2         |

其中三次测试执行时间在2秒内，t.N表示一共执行了多少次，op表示一次操作，alloc表示分配的内存。结果与我们的预期是相同的，我们自定义的序列化在性能上是秒杀其它各类序列化框架的，不过缺点就是要自己实现，有点累人哈。

> 这就是通常情况下，我们定义的消息头都是使用自定义序列化来实现的原因，可以实现空间与性能的最大化。

## 粘包与拆包

粘包与拆包原理实际上非常简单，就比如我们向一个文件中不停写入信息，如果没有固定的格式（比如使用\n区分），那么在读取时就无法区分每个信息的起始位置。大多数读者接触到的web系统中，都不用关心这个问题，因为使用http协议或者RPC协议时底层已经帮我们处理好了，但是在长连系统中底层需要我们自己处理，因此才需要关心这个问题。

在通信协议之状态篇中，我们介绍过TCP协议是面向字节流传输数据的，也就是说传输的数据是无边界的。TCP有读写缓冲区，应用程序通过Socket接口写入缓冲的数据不一定马上被封装成一个TCP包发送出去。TCP的可靠性中就包括了ACK机制，试想如果每次写一条消息到TCP缓冲都马上发送出去，发送5条消息就需要5条ACK，效率是很低的，如果我们把5个消息打包成一个TCP包发送出去，只需要一个ACK就可以了。

<div class="image-container">
    <img src="./docs/im/images/44.png" alt="图片8-8" title="图片8-8" >
    <span class="image-title">图 8-8 </span>
</div>

另一个影响因素与缓冲区空间大小有关，由于此时接收端的读缓冲可能只能存放3条消息，因此TCP通过窗口控制，可能的情况就是把这5个包分两次发送，第一次有3条消息封装成一个TCP包发送出去，等到接收端上层应用程序读取了一些数据，此时TCP读缓冲就有空闲的空间，发送方就可以把另外的2条消息打包发送过去了。

> 简单来说就是因为tcp协议中没有定义数据包大小，只校验数据完整性。

### 拆包

其实其中一个方法，在前面的序列化中已经给出了解答，因为知道消息的结构，就可以直接解析出来。当然还有其它办法，比如

1. 消息的长度固定（会有一定浪费）
2. 发送时写入：消息长度+消息
3. 使用分隔符，如 消息+'\n'

> 以上是协议层的逻辑决定的。但是在应用层，如果我们把多个数据包写入应用层缓冲之后，再一次性写入TCP缓冲，是可以提高效率的，但这也会导致多个包粘在一起。

### 缓冲区

在计算机中，缓冲无处不在，导致它存在的主要原因就是速度的不对等，缓冲区有buffer缓冲区和Cache缓存区两种，这里我们主要介绍buffer缓冲区在通信过程中的使用场景。

首先，TCP缓冲读写区已经在基础篇：通信协议之行为篇中介绍过了，这里就不再说明。而应用层缓冲就是指在我们编写网络应用程序时，为了减少IO读写操作，通常会在应用层定义读写缓冲区，通过批量操作就可以把多次IO操作变成一次IO操作，提高系统并发性能。

比如应用程序要向tcp连接中发送消息时，可以把数据发送到缓冲区然后直接返回，由另一个线程批量把缓冲区的数据一次性写入tcp写缓冲区。读缓冲的原理一样，通过一次性读取一个缓冲区的数据（比如4K），然后在应用层把消息包拆开。这里就会导致一个有趣的问题，就是缓冲区导致的粘包。我们以写缓冲为例：

> 写缓冲粘包是指在用户态进程中，为了提高IO性能，把多个数据包写入一个缓冲，然后一次性Flush到内核态TCP缓冲。

<div class="image-container">
    <img src="./docs/im/images/45.png" alt="图片8-9" title="图片8-9" >
    <span class="image-title">图 8-9 </span>
</div>

可以看到，无论底层协议是否会产生粘包情况，由于上层应用在写入时已经把多个包粘在一起了，在接收端读取出数据时，也是要拆包的。

> 搞懂了粘包的基本原理，相信读者以后就不会认为粘包只与tcp有关了！

### 魔数

魔数这个词在不同领域代表不同的含义。在计算机领域，魔数有两个含义，一指用来判断文件类型的魔数；二指程序代码中的魔数，也称魔法值。

在网络通信中，我们在协议头中加入魔数，有两个主要作用：

1. 快速过滤无效数据包。
2. 支持多种不同的协议。

但是读者需要注意的是，在网络中数据可能是非法或者被篡改过，因此设计魔数时有两个基本要求：

1. 长度不能太短。
2. 值不能简单。

比如我们设计一个值为0x01或者0x02这类的数据就没有太大的意义，一个非法的数据很容易就会命中这个值。下面我们设计两种不同的通信协议，其中都包括一个4字节的魔数；

协议一

| 魔数       | 消息长度 | 消息载体 |
| ---------- | -------- | -------- |
| 0xf9e8a6c5 | 4bytes   | n bytes  |

协议二

| 魔数       | 协议ID | 序列号 | 消息体长 | 消息体  |
| ---------- | ------ | ------ | -------- | ------- |
| 0xf1e2b3d4 | 2bytes | 4bytes | 4bytes   | n bytes |

1. 协议一在底层不关心协议任何数据，读取出消息载体之后就回调给上层处理。
2. 协议二的头部长度固定，有协议ID与序列号，底层在解出协议头部之后就可以根据协议ID来作出对应的处理。

可以看到，这两个协议的格式是实现不同的，在解析数据包，只需要判断二进制流中前面的4字节的值就可以判断出数据是否正确，以及协议格式。

本章完！
